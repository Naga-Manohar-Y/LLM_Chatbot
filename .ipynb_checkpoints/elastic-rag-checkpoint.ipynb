{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdbd20a-c005-4369-8fbf-8f5d2a97cde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6532c9af-8e89-4ed6-b6c1-815188dcdaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-20 16:06:52--  https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json\n",
      "Resolving github.com (github.com)... 140.82.112.4\n",
      "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/alexeygrigorev/llm-rag-workshop/main/notebooks/documents.json [following]\n",
      "--2024-06-20 16:06:53--  https://raw.githubusercontent.com/alexeygrigorev/llm-rag-workshop/main/notebooks/documents.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 658332 (643K) [text/plain]\n",
      "Saving to: ‘documents.json’\n",
      "\n",
      "documents.json      100%[===================>] 642.90K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-06-20 16:06:53 (26.7 MB/s) - ‘documents.json’ saved [658332/658332]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a8ecbb-ac7c-4893-8ee8-cc5360ad0885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"documents\": [\n",
      "      {\n",
      "        \"text\": \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \\u201cOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon\\u2019t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
      "        \"section\": \"General course-related questions\",\n",
      "        \"question\": \"Course - When will the course start?\"\n",
      "      },\n",
      "      {\n"
     ]
    }
   ],
   "source": [
    "!head documents.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927e34bf-2110-4b3e-b1bd-41da48b52306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./documents.json', 'rt') as f_in:\n",
    "    documents_file = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_file:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b9168e-afa8-4110-8398-2b082c023a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11032a99-f718-42ae-bf4f-291774ace2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3031d5b-23e9-49f4-b8f1-f48a7ebdcb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '4ea38fb27701', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'yAj8Ja9JSLy5jFdjF0-2lg', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6defb04f-f11a-446d-8f3c-2f4e52d4d8ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'resource_already_exists_exception', 'index [course-questions/JZ8S3gWhRziYGIE1WHxgXw] already exists')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m index_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msettings\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_of_shards\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     }\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     16\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcourse-questions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m response\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/LLM_Chatbot-wHvY14vo/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py:446\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/LLM_Chatbot-wHvY14vo/lib/python3.10/site-packages/elasticsearch/_sync/client/indices.py:553\u001b[0m, in \u001b[0;36mIndicesClient.create\u001b[0;34m(self, index, aliases, error_trace, filter_path, human, mappings, master_timeout, pretty, settings, timeout, wait_for_active_shards, body)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     __headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPUT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindices.create\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__path_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/LLM_Chatbot-wHvY14vo/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:423\u001b[0m, in \u001b[0;36mNamespacedClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    412\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# Use the internal clients .perform_request() implementation\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# so we take advantage of their transport options.\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/LLM_Chatbot-wHvY14vo/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    257\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ApiResponse[Any]:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_otel\u001b[38;5;241m.\u001b[39mspan(\n\u001b[1;32m    267\u001b[0m         method,\n\u001b[1;32m    268\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[1;32m    269\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    270\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[0;32m--> 271\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         otel_span\u001b[38;5;241m.\u001b[39mset_elastic_cloud_metadata(response\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/LLM_Chatbot-wHvY14vo/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:352\u001b[0m, in \u001b[0;36mBaseClient._perform_request\u001b[0;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    350\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(meta\u001b[38;5;241m.\u001b[39mstatus, ApiError)(\n\u001b[1;32m    353\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage, meta\u001b[38;5;241m=\u001b[39mmeta, body\u001b[38;5;241m=\u001b[39mresp_body\n\u001b[1;32m    354\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verified_elasticsearch:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: BadRequestError(400, 'resource_already_exists_exception', 'index [course-questions/JZ8S3gWhRziYGIE1WHxgXw] already exists')"
     ]
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "response = es.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feea8c64-23b1-425e-ab15-8b98ea9af760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/share/virtualenvs/LLM_Chatbot-wHvY14vo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [00:25<00:00, 37.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    es.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e28b1c59-8b93-405c-90cd-aa354c43aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"How do I join the course after it has started?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42fc4c7b-7ff6-4d1f-a540-b860255e10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": user_question,\n",
    "                    \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"data-engineering-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6e1ad6-59cd-46f8-b05c-0d66ca0fa524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 13, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 407, 'relation': 'eq'}, 'max_score': 53.20021, 'hits': [{'_index': 'course-questions', '_id': 'vDNwNpABn-wCoq2LaOA6', '_score': 53.20021, '_source': {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'section': 'General course-related questions', 'question': 'Course - Can I still join the course after the start date?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'wTNwNpABn-wCoq2LaODA', '_score': 47.001244, '_source': {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.', 'section': 'General course-related questions', 'question': 'Course - Can I follow the course after it finishes?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'vjNwNpABn-wCoq2LaOB4', '_score': 35.42595, '_source': {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.', 'section': 'General course-related questions', 'question': 'Course - What can I do before the course starts?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': '4zNwNpABn-wCoq2LbOBj', '_score': 33.921974, '_source': {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/', 'section': 'General course-related questions', 'question': 'How do I use Git / GitHub for this course?', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'VjNwNpABn-wCoq2LlOIw', '_score': 27.163462, '_source': {'text': \"Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\", 'section': 'Workshop 1 - dlthub', 'question': 'How do I install the necessary dependencies to run the code?', 'course': 'data-engineering-zoomcamp'}}]}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = es.search(index=index_name, body=search_query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d045c4dc-4a20-47e3-a765-d2e5ac133183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section: General course-related questions\n",
      "Question: Course - Can I still join the course after the start date?\n",
      "Answer: Yes, even if you don't register, you're still eligible to su...\n",
      "\n",
      "Section: General course-related questions\n",
      "Question: Course - Can I follow the course after it finishes?\n",
      "Answer: Yes, we will keep all the materials after the course finishe...\n",
      "\n",
      "Section: General course-related questions\n",
      "Question: Course - What can I do before the course starts?\n",
      "Answer: You can start by installing and setting up all the dependenc...\n",
      "\n",
      "Section: General course-related questions\n",
      "Question: How do I use Git / GitHub for this course?\n",
      "Answer: After you create a GitHub account, you should clone the cour...\n",
      "\n",
      "Section: Workshop 1 - dlthub\n",
      "Question: How do I install the necessary dependencies to run the code?\n",
      "Answer: Answer: To run the provided code, ensure that the 'dlt[duckd...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hit in response['hits']['hits']:\n",
    "    doc = hit['_source']\n",
    "    print(f\"Section: {doc['section']}\")\n",
    "    print(f\"Question: {doc['question']}\")\n",
    "    print(f\"Answer: {doc['text'][:60]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af77bea-03bb-4b6b-abc3-e0ac8867ea9c",
   "metadata": {},
   "source": [
    "## Clean coding - add this into in a function and structure it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c84276d-db06-4177-993a-c7ea4e7e97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "def retrieve_documents(query, index_name=\"course-questions\", max_results=5):\n",
    "    search_query = {\n",
    "        \"size\": max_results,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=index_name, body=search_query)\n",
    "    documents = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cc7d222-24e0-4331-a494-e9831d3187c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section: General course-related questions\n",
      "Question: Course - Can I still join the course after the start date?\n",
      "Answer: Yes, even if you don't register, you're still eligible to su...\n",
      "\n",
      "Section: General course-related questions\n",
      "Question: Course - Can I follow the course after it finishes?\n",
      "Answer: Yes, we will keep all the materials after the course finishe...\n",
      "\n",
      "Section: General course-related questions\n",
      "Question: Course - What can I do before the course starts?\n",
      "Answer: You can start by installing and setting up all the dependenc...\n",
      "\n",
      "Section: General course-related questions\n",
      "Question: How do I use Git / GitHub for this course?\n",
      "Answer: After you create a GitHub account, you should clone the cour...\n",
      "\n",
      "Section: Workshop 1 - dlthub\n",
      "Question: How do I install the necessary dependencies to run the code?\n",
      "Answer: Answer: To run the provided code, ensure that the 'dlt[duckd...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_question = \"How do I join the course after it has started?\"\n",
    "\n",
    "response = retrieve_documents(user_question)\n",
    "\n",
    "for doc in response:\n",
    "    print(f\"Section: {doc['section']}\")\n",
    "    print(f\"Question: {doc['question']}\")\n",
    "    print(f\"Answer: {doc['text'][:60]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc207f-cd15-475f-a038-63fcefe9f540",
   "metadata": {},
   "source": [
    "### Connecting with MistralAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23558125-140d-4c21-92f5-c056eb2d922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "api_key = os.getenv('MISTRAL_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please set the MISTRAL_API_KEY environment variable.\")\n",
    "\n",
    "# Initialize the client with the retrieved API key\n",
    "client = MistralClient(api_key=api_key)\n",
    "def llm(prompt):\n",
    "    response = client.chat(\n",
    "        model='open-mistral-7b',\n",
    "        messages=[\n",
    "            ChatMessage(role=\"user\", content=prompt)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dadc1c08-40f1-4dfc-9bd7-dc2908821ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a model of an artificial intelligence designed to assist with a wide variety of tasks. I can help answer questions, provide information, and assist with tasks such as scheduling, reminders, and more. I'm here to make your life easier and more convenient. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Who are you ?\"\n",
    "response = llm(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc13d14-37f7-42d8-95e0-8955e94aba00",
   "metadata": {},
   "source": [
    "### Building the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df2b4292-d8f7-46e0-9d70-1da57ce114a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section: General course-related questions\n",
      "Question: Course - Can I still join the course after the start date?\n",
      "Answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "Section: General course-related questions\n",
      "Question: Course - Can I follow the course after it finishes?\n",
      "Answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "Section: General course-related questions\n",
      "Question: Course - What can I do before the course starts?\n",
      "Answer: You can start by installing and setting up all the dependencies and requirements:\n",
      "Google cloud account\n",
      "Google Cloud SDK\n",
      "Python 3 (installed with Anaconda)\n",
      "Terraform\n",
      "Git\n",
      "Look over the prerequisites and syllabus to see if you are comfortable with these subjects.\n",
      "\n",
      "Section: General course-related questions\n",
      "Question: How do I use Git / GitHub for this course?\n",
      "Answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "Section: Workshop 1 - dlthub\n",
      "Question: How do I install the necessary dependencies to run the code?\n",
      "Answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n"
     ]
    }
   ],
   "source": [
    "context_template = \"\"\"\n",
    "Section: {section}\n",
    "Question: {question}\n",
    "Answer: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "context_docs = retrieve_documents(user_question)\n",
    "\n",
    "context_result = \"\"\n",
    "\n",
    "for doc in context_docs:\n",
    "    doc_str = context_template.format(**doc)\n",
    "    context_result += (\"\\n\\n\" + doc_str)\n",
    "\n",
    "context = context_result.strip()\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e9ad7-add0-420f-bc30-319cf2918900",
   "metadata": {},
   "source": [
    "### Building the prompt along with context (search results from our data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2e4cf41-a130-4dae-a3f0-4498b2eec9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_prompt = f\"\"\"\n",
    "You're a course teaching assistant. Answer the user QUESTION based on CONTEXT - the documents retrieved from our FAQ database. \n",
    "Only use the facts from the CONTEXT. If the CONTEXT doesn't contan the answer, return \"NONE\"\n",
    "\n",
    "QUESTION: {user_question}\n",
    "\n",
    "CONTEXT:\n",
    "\n",
    "{context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8adb4b39-22df-4fac-9c0e-8ec521d3cf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To join the course after it has started, you can still submit the homeworks even if you didn't register initially. However, be aware of the deadlines for turning in the final projects. The course materials will be kept after it finishes, so you can follow the course at your own pace afterwards. Before the course starts, you can prepare by installing and setting up all the dependencies and requirements such as Google Cloud account, Google Cloud SDK, Python 3 with Anaconda, Terraform, Git, and reviewing the prerequisites and syllabus.\n",
      "\n",
      "For using Git/GitHub, you should create a GitHub account and clone the course repo to your local machine. You can also create your own repositories to host your notes and versions of your files. Remember to ignore large files that shouldn't be saved to a repository and use .gitignore for this. Never store passwords or keys in a git repo, even if it's set to private.\n",
      "\n",
      "For running the provided code, ensure that the 'dlt[duckdb]' package is installed by executing the command: !pip install dlt[duckdb]. If you're doing it locally, also have duckdb pip installed before the duckdb package is loaded.\n"
     ]
    }
   ],
   "source": [
    "response = llm(actual_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58adda45-2771-4556-9fa1-7e704b852220",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_template = \"\"\"\n",
    "Section: {section}\n",
    "Question: {question}\n",
    "Answer: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "Answer the user QUESTION based on CONTEXT - the documents retrieved from our FAQ database.\n",
    "Don't use other information outside of the provided CONTEXT.  \n",
    "\n",
    "QUESTION: {user_question}\n",
    "\n",
    "CONTEXT:\n",
    "\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_context(documents):\n",
    "    context_result = \"\"\n",
    "    \n",
    "    for doc in documents:\n",
    "        doc_str = context_template.format(**doc)\n",
    "        context_result += (\"\\n\\n\" + doc_str)\n",
    "    \n",
    "    return context_result.strip()\n",
    "\n",
    "def build_prompt(user_question, documents):\n",
    "    context = build_context(documents)\n",
    "    prompt = prompt_template.format(\n",
    "        user_question=user_question,\n",
    "        context=context\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def ask_mistral(prompt, model=\"open-mistral-7b\"):\n",
    "    response = client.chat(\n",
    "        model=model,\n",
    "        messages=[ChatMessage(role=\"user\", content=prompt)]\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "def qa_bot(user_question):\n",
    "    context_docs = retrieve_documents(user_question)  # Assuming this function is defined elsewhere\n",
    "    prompt = build_prompt(user_question, context_docs)\n",
    "    answer = ask_mistral(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d32962c6-c67a-4e00-b61e-14ed9832ff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The issue you\\'re encountering is related to Docker and specifically the format of the volume mount when running a container. The error message you\\'re seeing (\"invalid reference format: repository name must be lowercase\") is not directly related to the issue at hand, but it\\'s worth noting that repository names in Docker should indeed be lowercase.\\n\\nIn your case, it seems like the problem is with the format of the volume mount. The context provided suggests that you can try different ways to format the volume mount, such as:\\n\\n- Using forward slashes (`/`) or backslashes (`\\\\`) before the path:\\n  - `-v /c:/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data`\\n  - `-v //c:/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data`\\n\\n- Using quotes around the path:\\n  - `-v \"/c:/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\"`\\n  - `-v \"//c:/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\"`\\n  - `-v “/c/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\"`\\n  - `-v \"//c/some/path/ny_taxi_postgres_data:/var/lib/postgresql/data\"`\\n  - `-v \"c:\\\\some\\\\path\\\\ny_taxi_postgres_data\":/var/lib/postgresql/data`\\n\\n- Using a volume name instead of the path:\\n  - `-v ny_taxi_postgres_data:/var/lib/postgresql/data`\\n\\nRemember to delete any existing folders that Docker might have created if you encounter issues with volume mapping. Also, take note of the position of the quotes in the examples provided.\\n\\nIf none of these options work, you might want to consider rechecking your Docker installation and environment variables to ensure they are correctly set up.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot(\"I'm getting invalid reference format: repository name must be lowercase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e182bcd1-1895-4e7b-9270-c0217cf7132a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems that you're encountering a password authentication failure when trying to connect to PostgreSQL on port 5432. This issue can occur due to several reasons, such as incorrect password, conflicting PostgreSQL installations, or port conflicts.\\n\\nIn your case, it's possible that you have a local PostgreSQL installation on your machine, which is causing the conflict with the Docker container. To resolve this issue, you can follow these steps:\\n\\n1. Change the port that the Docker container uses for PostgreSQL. Instead of mapping port 5432, use another available port, such as 5431. Here's an example of how to change the port:\\n\\n   ```\\n   docker run -p 5431:5432 <your_postgres_image>\\n   ```\\n\\n2. Update your connection string in your application to use the new port. For example, if you're using `psycopg2` in Python:\\n\\n   ```\\n   engine = create_engine('postgresql://root:root@localhost:5431/ny_taxi')\\n   ```\\n\\n3. Make sure to update your connection string in pgcli as well:\\n\\n   ```\\n   pgcli -h localhost -p 5431 -U root -d ny_taxi\\n   ```\\n\\n4. If you still encounter issues, check if there is a running PostgreSQL service on your machine. If so, you can stop it and free up the port. On a MacOS, you can do this by unloading the launch agent for the PostgreSQL service:\\n\\n   ```\\n   launchctl unload -w ~/Library/LaunchAgents/homebrew.mxcl.postgresql.plist\\n   ```\\n\\n   Afterwards, you can start the service again:\\n\\n   ```\\n   launchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.postgresql.plist\\n   ```\\n\\nBy following these steps, you should be able to connect to your PostgreSQL container on the new port without any password authentication issues.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot(\"I can't connect to postgres port 5432, my password doesn't work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "049729f3-7dd0-426d-9cc5-d117843f7313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To run Kafka, follow the steps below:\\n\\n1. First, create a virtual environment and install the necessary packages. (Note: This step is only needed if you're running the Kafka producer or consumer without using Docker):\\n\\n   ```\\n   python -m venv env\\n   source env/bin/activate\\n   pip install -r ../requirements.txt\\n   ```\\n\\n   (If you're using Windows, use `env\\\\Scripts\\\\activate` instead of `source env/bin/activate`)\\n\\n2. Now, navigate to the location of your Kafka project (where the producer or consumer scripts are located).\\n\\n3. To run a Kafka producer or consumer, use the following command format:\\n\\n   ```\\n   java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/<producer_or_consumer_class>.java\\n   ```\\n\\n   Replace `<jar_name>` with the name of the jar file and `<producer_or_consumer_class>` with the name of the class that extends `KafkaProducer` (for producer) or `KafkaConsumer` (for consumer).\\n\\nIf you're using Docker images, make sure that they are up and running before running the Kafka producer or consumer.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot(\"how can I run kafka?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3658c-c201-4354-ad91-3f80d637995c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
